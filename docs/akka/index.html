<!DOCTYPE html><html><head><title>documentation: Integration with Akka Streams</title><meta charset="utf-8" /><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" /><meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="author" content="Marcin Jakubowski" /><meta name="description" content="Read and write Parquet files using Scala" /><meta name="og:image" content="/parquet4s/img/poster.png" /><meta name="image" property="og:image" content="/parquet4s/img/poster.png" /><meta name="og:title" content="documentation: Integration with Akka Streams" /><meta name="title" property="og:title" content="documentation: Integration with Akka Streams" /><meta name="og:site_name" content="documentation" /><meta name="og:url" content="" /><meta name="og:type" content="website" /><meta name="og:description" content="Read and write Parquet files using Scala" /><link rel="icon" type="image/png" href="/parquet4s/img/favicon.png" /><meta name="twitter:title" content="documentation: Integration with Akka Streams" /><meta name="twitter:image" content="/parquet4s/img/poster.png" /><meta name="twitter:description" content="Read and write Parquet files using Scala" /><meta name="twitter:card" content="summary_large_image" /><link rel="icon" type="image/png" sizes="16x16" href="/parquet4s/img/favicon-16x16.png" /><link rel="icon" type="image/png" sizes="32x32" href="/parquet4s/img/favicon-32x32.png" /><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" /><link rel="stylesheet" href="/parquet4s/highlight/styles/vs.css" /><link rel="stylesheet" href="/parquet4s/css/light-style.css" /></head><body class="docs"><div id="wrapper"><div id="sidebar-wrapper"><div id="sidebar-brand"><a href="/parquet4s/" class="brand"><div class="brand-wrapper"></div><span>documentation</span></a><button id="main-toggle" class="sidebar-toggle"><span class="close"></span></button></div><div class="sidebar-nav"> <div class="sidebar-nav-item  "><a href="/parquet4s/docs" title="Introduction" class="">Introduction</a></div> <div class="sidebar-nav-item  "><a href="/parquet4s/docs/quick_start" title="Quick Start" class="">Quick Start</a></div> <div class="sidebar-nav-item active "><a href="/parquet4s/docs/akka" title="Integration with Akka Streams" class="active">Integration with Akka Streams</a></div> <div class="sidebar-nav-item  "><a href="/parquet4s/docs/pekko" title="Integration with Pekko Streams" class="">Integration with Pekko Streams</a></div> <div class="sidebar-nav-item  "><a href="/parquet4s/docs/fs2" title="Integration with FS2" class="">Integration with FS2</a></div> <div class="sidebar-nav-item  "><a href="/parquet4s/docs/storage_types" title="Supported storage types" class="">Supported storage types</a></div> <div class="sidebar-nav-item  "><a href="/parquet4s/docs/records_and_schema" title="Records, types and schema" class="">Records, types and schema</a></div> <div class="sidebar-nav-item  "><a href="/parquet4s/docs/projection" title="Projection" class="">Projection</a></div> <div class="sidebar-nav-item  "><a href="/parquet4s/docs/filtering" title="Filtering" class="">Filtering</a></div> <div class="sidebar-nav-item  "><a href="/parquet4s/docs/partitioning" title="Partitioning" class="">Partitioning</a></div> <div class="sidebar-nav-item  "><a href="/parquet4s/docs/statistics" title="Statistics" class="">Statistics</a></div> <div class="sidebar-nav-item  "><a href="/parquet4s/docs/examples" title="Examples" class="">Examples</a></div> <div class="sidebar-nav-item  "><a href="/parquet4s/docs/migration" title="Migration from 1.x" class="">Migration from 1.x</a></div> <div class="sidebar-nav-item  "><a href="/parquet4s/docs/experimental" title="(Experimental) ETL" class="">(Experimental) ETL</a></div> <div class="sidebar-nav-item  "><a href="/parquet4s/docs/protobuf" title="(Experimental) Protobuf" class="">(Experimental) Protobuf</a></div> <div class="sidebar-nav-item  "><a href="/parquet4s/docs/sponsors" title="Distinguished Sponsors" class="">Distinguished Sponsors</a></div></div></div><div id="page-content-wrapper"><div class="nav"><div class="container-fluid"><div class="row"><div class="col-lg-12"><div class="action-menu pull-left clearfix"><a href="#menu-toggle" id="menu-toggle"><i class="fa fa-bars" aria-hidden="true"></i></a></div><ul class="pull-right"><li class="search-nav"><div id="search-dropdown"><label><i class="fa fa-search"></i>Search</label><input id="search-bar" type="text" placeholder="Enter keywords here..." onclick="displayToggleSearch(event)" /><ul id="search-dropdown-content" class="dropdown dropdown-content"></ul></div></li><li id="gh-eyes-item" class="hidden-xs to-uppercase"><a href="https://github.com/mjakubowski84/parquet4s" target="_blank" rel="noopener noreferrer"><i class="fa fa-eye"></i><span>Watchers<span id="eyes" class="label label-default">--</span></span></a></li><li id="gh-stars-item" class="hidden-xs to-uppercase"><a href="https://github.com/mjakubowski84/parquet4s" target="_blank" rel="noopener noreferrer"><i class="fa fa-star-o"></i><span>Stars<span id="stars" class="label label-default">--</span></span></a></li></ul></div></div></div></div><div id="content" data-github-owner="mjakubowski84" data-github-repo="parquet4s"><div class="content-wrapper"><section><h1 id="integration-with-akka-streams">Integration with Akka Streams</h1>

<p>Parquet4s has an integration module that allows you to read and write Parquet files using Akka Streams. Just import:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">"com.github.mjakubowski84"</span> <span class="o">%%</span> <span class="s">"parquet4s-akka"</span> <span class="o">%</span> <span class="s">"2.16.0-SNAPSHOT"</span>
<span class="s">"org.apache.hadoop"</span> <span class="o">%</span> <span class="s">"hadoop-client"</span> <span class="o">%</span> <span class="n">yourHadoopVersion</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">ParquetStreams</code> has a single <code class="language-plaintext highlighter-rouge">Source</code> for reading a single file or a directory (can be <a href="/parquet4s/docs/partitioning/">partitioned</a>), a <code class="language-plaintext highlighter-rouge">Sink</code>s for writing a single file and a sophisticated <code class="language-plaintext highlighter-rouge">Flow</code> for performing complex writes.</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">akka.NotUsed</span>
<span class="k">import</span> <span class="nn">akka.actor.ActorSystem</span>
<span class="k">import</span> <span class="nn">akka.stream.scaladsl.Source</span>
<span class="k">import</span> <span class="nn">com.github.mjakubowski84.parquet4s.</span><span class="o">{</span><span class="nc">ParquetReader</span><span class="o">,</span> <span class="nc">ParquetStreams</span><span class="o">,</span> <span class="nc">ParquetWriter</span><span class="o">,</span> <span class="nc">Path</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.parquet.hadoop.ParquetFileWriter.Mode</span>
<span class="k">import</span> <span class="nn">org.apache.parquet.hadoop.metadata.CompressionCodecName</span>
<span class="k">import</span> <span class="nn">org.apache.parquet.hadoop.</span><span class="o">{</span><span class="nc">ParquetWriter</span> <span class="k">=&gt;</span> <span class="nc">HadoopParquetWriter</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.hadoop.conf.Configuration</span>

<span class="k">import</span> <span class="nn">scala.concurrent.duration._</span>

<span class="k">case</span> <span class="k">class</span> <span class="nc">User</span><span class="o">(</span><span class="n">userId</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">name</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">created</span><span class="k">:</span> <span class="kt">java.sql.Timestamp</span><span class="o">)</span>

<span class="k">implicit</span> <span class="k">val</span> <span class="nv">system</span><span class="k">:</span> <span class="kt">ActorSystem</span> <span class="o">=</span> <span class="nc">ActorSystem</span><span class="o">()</span>

<span class="k">val</span> <span class="nv">users</span><span class="k">:</span> <span class="kt">Source</span><span class="o">[</span><span class="kt">User</span>, <span class="kt">NotUsed</span><span class="o">]</span> <span class="k">=</span> <span class="o">???</span>

<span class="k">val</span> <span class="nv">conf</span><span class="k">:</span> <span class="kt">Configuration</span> <span class="o">=</span> <span class="o">???</span> <span class="c1">// Set Hadoop configuration programmatically // Set Hadoop configuration programmatically</span>

<span class="c1">// Please check all the available configuration options!</span>
<span class="k">val</span> <span class="nv">writeOptions</span> <span class="k">=</span> <span class="nv">ParquetWriter</span><span class="o">.</span><span class="py">Options</span><span class="o">(</span>
  <span class="n">writeMode</span> <span class="k">=</span> <span class="nv">Mode</span><span class="o">.</span><span class="py">OVERWRITE</span><span class="o">,</span>
  <span class="n">compressionCodecName</span> <span class="k">=</span> <span class="nv">CompressionCodecName</span><span class="o">.</span><span class="py">SNAPPY</span><span class="o">,</span>
  <span class="n">hadoopConf</span> <span class="k">=</span> <span class="n">conf</span> <span class="c1">// optional hadoopConf</span>
<span class="o">)</span>

<span class="c1">// Writes a single file.</span>
<span class="nv">users</span><span class="o">.</span><span class="py">runWith</span><span class="o">(</span>
  <span class="nc">ParquetStreams</span>
    <span class="o">.</span><span class="py">toParquetSingleFile</span>
    <span class="o">.</span><span class="py">of</span><span class="o">[</span><span class="kt">User</span><span class="o">]</span>
    <span class="o">.</span><span class="py">options</span><span class="o">(</span><span class="n">writeOptions</span><span class="o">)</span>
    <span class="o">.</span><span class="py">write</span><span class="o">(</span><span class="nc">Path</span><span class="o">(</span><span class="s">"file:///data/users/user-303.parquet"</span><span class="o">))</span>
<span class="o">)</span>

<span class="c1">// Tailored for writing indefinite streams.</span>
<span class="c1">// Writes file when chunk reaches size limit and when defined time period elapses.</span>
<span class="c1">// Can also partition files!</span>
<span class="c1">// Check all the parameters and example usage in project sources.</span>
<span class="nv">users</span><span class="o">.</span><span class="py">via</span><span class="o">(</span>
  <span class="nc">ParquetStreams</span>
    <span class="o">.</span><span class="py">viaParquet</span>
    <span class="o">.</span><span class="py">of</span><span class="o">[</span><span class="kt">User</span><span class="o">]</span>
    <span class="o">.</span><span class="py">maxCount</span><span class="o">(</span><span class="nv">writeOptions</span><span class="o">.</span><span class="py">rowGroupSize</span><span class="o">)</span>
    <span class="o">.</span><span class="py">maxDuration</span><span class="o">(</span><span class="mf">30.</span><span class="n">seconds</span><span class="o">)</span>
    <span class="o">.</span><span class="py">options</span><span class="o">(</span><span class="n">writeOptions</span><span class="o">)</span>
    <span class="o">.</span><span class="py">write</span><span class="o">(</span><span class="nc">Path</span><span class="o">(</span><span class="s">"file:///data/users"</span><span class="o">))</span>
<span class="o">).</span><span class="py">runForeach</span><span class="o">(</span><span class="n">user</span> <span class="k">=&gt;</span> <span class="nf">println</span><span class="o">(</span><span class="n">s</span><span class="s">"Just wrote user ${user.userId}..."</span><span class="o">))</span>
  
<span class="c1">// Reads a file, files from the directory or a partitioned directory. </span>
<span class="c1">// Please also have a look at the rest of parameters.</span>
<span class="nc">ParquetStreams</span>
  <span class="o">.</span><span class="py">fromParquet</span>
  <span class="o">.</span><span class="py">as</span><span class="o">[</span><span class="kt">User</span><span class="o">]</span>
  <span class="o">.</span><span class="py">options</span><span class="o">(</span><span class="nv">ParquetReader</span><span class="o">.</span><span class="py">Options</span><span class="o">(</span><span class="n">hadoopConf</span> <span class="k">=</span> <span class="n">conf</span><span class="o">))</span>
  <span class="o">.</span><span class="py">read</span><span class="o">(</span><span class="nc">Path</span><span class="o">(</span><span class="s">"file:///data/users"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">runForeach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>

<span class="c1">// (Experimental API) Writes a single file using a custom ParquetWriter.</span>
<span class="k">class</span> <span class="nc">UserParquetWriterBuilder</span><span class="o">(</span><span class="n">path</span><span class="k">:</span> <span class="kt">Path</span><span class="o">)</span> <span class="k">extends</span> <span class="nv">HadoopParquetWriter</span><span class="o">.</span><span class="py">Builder</span><span class="o">[</span><span class="kt">User</span>, <span class="kt">UserParquetWriterBuilder</span><span class="o">](</span><span class="nv">path</span><span class="o">.</span><span class="py">toHadoop</span><span class="o">)</span> <span class="o">{</span>
  <span class="k">override</span> <span class="k">def</span> <span class="nf">self</span><span class="o">()</span> <span class="k">=</span> <span class="k">this</span>
  <span class="k">override</span> <span class="k">def</span> <span class="nf">getWriteSupport</span><span class="o">(</span><span class="n">conf</span><span class="k">:</span> <span class="kt">Configuration</span><span class="o">)</span> <span class="k">=</span> <span class="o">???</span>
<span class="o">}</span>
<span class="nv">users</span><span class="o">.</span><span class="py">runWith</span><span class="o">(</span>
  <span class="nc">ParquetStreams</span>
    <span class="o">.</span><span class="py">toParquetSingleFile</span>
    <span class="o">.</span><span class="py">custom</span><span class="o">[</span><span class="kt">User</span>, <span class="kt">UserParquetWriterBuilder</span><span class="o">](</span><span class="k">new</span> <span class="nc">UserParquetWriterBuilder</span><span class="o">(</span><span class="nc">Path</span><span class="o">(</span><span class="s">"file:///data/users/custom.parquet"</span><span class="o">)))</span>
    <span class="o">.</span><span class="py">options</span><span class="o">(</span><span class="n">writeOptions</span><span class="o">)</span>
    <span class="o">.</span><span class="py">write</span>
<span class="o">)</span>
</code></pre></div></div>

<p>Please check <a href="https://github.com/mjakubowski84/parquet4s/tree/master/examples/src/main/scala/com/github/mjakubowski84/parquet4s/akkaPekko">examples</a> to learn more.</p>
</section></div></div></div></div><script src="/parquet4s/highlight/highlight.pack.js"></script><script src="/parquet4s/lunr/lunr.js"></script><script>
// For all code blocks, copy the language from the containing div
// to the inner code tag (where hljs expects it to be)
const langPrefix = 'language-';
document.querySelectorAll(`div[class^='${langPrefix}']`).forEach(function(div) {
  div.classList.forEach(function(cssClass) {
    if (cssClass.startsWith(langPrefix)) {
      const lang = cssClass.substring(langPrefix.length);
      div.querySelectorAll('pre code').forEach(function(code) {
        code.classList.add(lang);
      });
    }
  });
});

hljs.configure({languages:['scala','java','bash']});
hljs.initHighlightingOnLoad();
      </script><script>console.info('\x57\x65\x62\x73\x69\x74\x65\x20\x62\x75\x69\x6c\x74\x20\x77\x69\x74\x68\x3a\x0a\x20\x20\x20\x20\x20\x20\x20\x20\x20\x5f\x5f\x20\x20\x20\x20\x5f\x5f\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x5f\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x5f\x20\x5f\x5f\x0a\x20\x20\x20\x5f\x5f\x5f\x5f\x5f\x2f\x20\x2f\x5f\x20\x20\x2f\x20\x2f\x5f\x20\x20\x20\x20\x20\x20\x5f\x5f\x5f\x5f\x20\x5f\x5f\x5f\x20\x20\x28\x5f\x29\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x20\x20\x5f\x5f\x5f\x5f\x5f\x28\x5f\x29\x20\x2f\x5f\x5f\x5f\x5f\x20\x20\x5f\x5f\x5f\x5f\x5f\x0a\x20\x20\x2f\x20\x5f\x5f\x5f\x2f\x20\x5f\x5f\x20\x5c\x2f\x20\x5f\x5f\x2f\x5f\x5f\x5f\x5f\x5f\x2f\x20\x5f\x5f\x20\x60\x5f\x5f\x20\x5c\x2f\x20\x2f\x20\x5f\x5f\x5f\x2f\x20\x5f\x5f\x5f\x2f\x20\x5f\x5f\x20\x5c\x2f\x20\x5f\x5f\x5f\x2f\x20\x2f\x20\x5f\x5f\x2f\x20\x5f\x20\x5c\x2f\x20\x5f\x5f\x5f\x2f\x0a\x20\x28\x5f\x5f\x20\x20\x29\x20\x2f\x5f\x2f\x20\x2f\x20\x2f\x5f\x2f\x5f\x5f\x5f\x5f\x5f\x2f\x20\x2f\x20\x2f\x20\x2f\x20\x2f\x20\x2f\x20\x2f\x20\x2f\x5f\x5f\x2f\x20\x2f\x20\x20\x2f\x20\x2f\x5f\x2f\x20\x28\x5f\x5f\x20\x20\x29\x20\x2f\x20\x2f\x5f\x2f\x20\x20\x5f\x5f\x28\x5f\x5f\x20\x20\x29\x0a\x2f\x5f\x5f\x5f\x5f\x2f\x5f\x2e\x5f\x5f\x5f\x2f\x5c\x5f\x5f\x2f\x20\x20\x20\x20\x20\x2f\x5f\x2f\x20\x2f\x5f\x2f\x20\x2f\x5f\x2f\x5f\x2f\x5c\x5f\x5f\x5f\x2f\x5f\x2f\x20\x20\x20\x5c\x5f\x5f\x5f\x5f\x2f\x5f\x5f\x5f\x5f\x2f\x5f\x2f\x5c\x5f\x5f\x2f\x5c\x5f\x5f\x5f\x2f\x5f\x5f\x5f\x5f\x2f\x0a\x0a\x68\x74\x74\x70\x73\x3a\x2f\x2f\x34\x37\x64\x65\x67\x2e\x67\x69\x74\x68\x75\x62\x2e\x69\x6f\x2f\x73\x62\x74\x2d\x6d\x69\x63\x72\x6f\x73\x69\x74\x65\x73')</script><script src="/parquet4s/js/search.js"></script><script src="/parquet4s/js/docs.js"></script></body></html>